#!/bin/bash -u

warmup_proportion=0.1
learning_rate=5e-5
train_batch_size=12
gradient_accumulation_steps=3
max_seq_len=128
n_epoch=3
model_name_or_path=bert-large-uncased
logging_steps=10
