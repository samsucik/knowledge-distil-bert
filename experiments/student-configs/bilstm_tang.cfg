#!/bin/bash -u
student_type=LSTM

n_epochs=30
checkpoint_interval=-1
batch_size=32      # best
gradient_accumulation_steps=1
log_interval=100

fc_size=2000
hidden_size=1500
n_layers_lstm=2
alpha_mse=1.0
alpha_ce=0.0
max_grad_norm=30000
temperature=0.0001
dropout=0.1
mode=multichannel
weight_decay=0.0

optimizer=adam     # best
learning_rate=5e-4 # best
warmup_epochs=0    # best
lr_decay=true      # best

use_hard_labels=false
token_embeddings_from_teacher=false # best
use_word_vectors=true               # best
token_embedding_dimensionality=300  # best
